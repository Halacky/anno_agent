"""
SAM3 + Qwen VLM Agent
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤
"""

import requests
import base64
import json
from typing import List, Dict, Optional, Union, Tuple
from dataclasses import dataclass
from io import BytesIO
from PIL import Image
import numpy as np


@dataclass
class BoundingBox:
    """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π bounding box [cx, cy, w, h]"""
    cx: float
    cy: float
    w: float
    h: float
    
    def to_list(self) -> List[float]:
        return [self.cx, self.cy, self.w, self.h]
    
    def to_xyxy(self, width: int, height: int) -> Tuple[int, int, int, int]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã [x1, y1, x2, y2]"""
        x1 = int((self.cx - self.w / 2) * width)
        y1 = int((self.cy - self.h / 2) * height)
        x2 = int((self.cx + self.w / 2) * width)
        y2 = int((self.cy + self.h / 2) * height)
        return (x1, y1, x2, y2)


@dataclass
class DetectedObject:
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏"""
    category: str
    bbox: BoundingBox
    confidence: float
    attributes: Optional[Dict] = None


@dataclass
class SegmentationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    mask: str  # RLE-encoded mask
    bbox: BoundingBox
    score: float
    object_info: Optional[DetectedObject] = None


class SAM3QwenAgent:
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è SAM3 –∏ Qwen VLM.
    
    Workflow:
    1. Qwen –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç—ã
    2. SAM3 –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ç–æ—á–Ω—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Qwen
    """
    
    def __init__(
        self,
        sam3_url: str = "http://localhost:8000",
        qwen_url: str = "http://localhost:8001",
        sam3_api_version: str = "v1",
        qwen_api_version: str = "v1"
    ):
        self.sam3_url = sam3_url.rstrip('/')
        self.qwen_url = qwen_url.rstrip('/')
        self.sam3_api_version = sam3_api_version
        self.qwen_api_version = qwen_api_version
        
    def _image_to_base64(self, image: Union[str, Image.Image, np.ndarray]) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64"""
        if isinstance(image, str):
            # –ï—Å–ª–∏ —ç—Ç–æ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            with open(image, 'rb') as f:
                return base64.b64encode(f.read()).decode('utf-8')
        elif isinstance(image, Image.Image):
            # PIL Image
            buffer = BytesIO()
            image.save(buffer, format='PNG')
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
        elif isinstance(image, np.ndarray):
            # NumPy array
            img = Image.fromarray(image)
            buffer = BytesIO()
            img.save(buffer, format='PNG')
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
        else:
            raise ValueError("Unsupported image type")
    
    def detect_objects_with_qwen(
        self,
        image: Union[str, Image.Image, np.ndarray],
        categories: Optional[List[str]] = None,
        custom_prompt: Optional[str] = None,
        include_attributes: bool = True
    ) -> List[DetectedObject]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é Qwen VLM
        
        Args:
            image: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, PIL Image –∏–ª–∏ NumPy array
            categories: –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ (–µ—Å–ª–∏ None, —Ç–æ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã)
            custom_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è Qwen
            include_attributes: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å bounding boxes
        """
        image_b64 = self._image_to_base64(image)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ Qwen –¥–ª—è 2D grounding
        payload = {
            "image_base64": image_b64,
            "include_attributes": include_attributes
        }
        
        if categories:
            payload["categories"] = categories
        
        if custom_prompt:
            payload["prompt"] = custom_prompt
        
        url = f"{self.qwen_url}/api/{self.qwen_api_version}/grounding/2d"
        response = requests.post(url, json=payload)
        response.raise_for_status()
        
        result = response.json()
        
        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        detected_objects = []
        for detection in result.get('detections', []):
            bbox_data = detection.get('bbox', {})
            bbox = BoundingBox(
                cx=bbox_data.get('cx', 0),
                cy=bbox_data.get('cy', 0),
                w=bbox_data.get('w', 0),
                h=bbox_data.get('h', 0)
            )
            
            obj = DetectedObject(
                category=detection.get('category', 'unknown'),
                bbox=bbox,
                confidence=detection.get('confidence', 0.0),
                attributes=detection.get('attributes')
            )
            detected_objects.append(obj)
        
        return detected_objects
    
    def segment_with_sam3(
        self,
        image: Union[str, Image.Image, np.ndarray],
        prompts: List[Dict],
        confidence_threshold: float = 0.5
    ) -> List[SegmentationResult]:
        """
        –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é SAM3
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            prompts: –°–ø–∏—Å–æ–∫ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è SAM3
            confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        """
        image_b64 = self._image_to_base64(image)
        
        payload = {
            "image": image_b64,
            "prompts": prompts,
            "confidence_threshold": confidence_threshold
        }
        
        url = f"{self.sam3_url}/api/{self.sam3_api_version}/image/segment"
        response = requests.post(url, json=payload)
        response.raise_for_status()
        
        result = response.json()
        
        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        segmentations = []
        for i in range(result['num_masks']):
            bbox_list = result['boxes'][i]
            bbox = BoundingBox(
                cx=bbox_list[0],
                cy=bbox_list[1],
                w=bbox_list[2],
                h=bbox_list[3]
            )
            
            seg = SegmentationResult(
                mask=result['masks'][i],
                bbox=bbox,
                score=result['scores'][i]
            )
            segmentations.append(seg)
        
        return segmentations
    
    def analyze_and_segment(
        self,
        image: Union[str, Image.Image, np.ndarray],
        query: str,
        categories: Optional[List[str]] = None,
        confidence_threshold: float = 0.5,
        use_text_prompts: bool = True
    ) -> List[SegmentationResult]:
        """
        –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∞–Ω–∞–ª–∏–∑ —Å Qwen + —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å SAM3
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            query: –ó–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–Ω–∞–π–¥–∏ –≤—Å–µ –º–∞—à–∏–Ω—ã")
            categories: –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
            confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è SAM3
            use_text_prompts: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è SAM3
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –æ–±—ä–µ–∫—Ç–∞—Ö
        """
        print(f"üîç –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å Qwen VLM...")
        print(f"   –ó–∞–ø—Ä–æ—Å: {query}")
        
        # –®–∞–≥ 1: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ —Å Qwen
        detected_objects = self.detect_objects_with_qwen(
            image=image,
            categories=categories,
            custom_prompt=query,
            include_attributes=True
        )
        
        print(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(detected_objects)}")
        for obj in detected_objects:
            print(f"   - {obj.category} (confidence: {obj.confidence:.2f})")
        
        if not detected_objects:
            print("‚ö†Ô∏è  –û–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return []
        
        # –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è SAM3
        sam3_prompts = []
        
        for obj in detected_objects:
            if use_text_prompts:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
                text_description = obj.category
                if obj.attributes:
                    attrs = ", ".join([f"{k}: {v}" for k, v in obj.attributes.items()])
                    text_description = f"{obj.category} ({attrs})"
                
                sam3_prompts.append({
                    "type": "text",
                    "text": text_description
                })
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º bounding box –ø—Ä–æ–º–ø—Ç
                sam3_prompts.append({
                    "type": "box",
                    "box": obj.bbox.to_list(),
                    "label": True
                })
        
        print(f"\nüéØ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å SAM3...")
        print(f"   –ü—Ä–æ–º–ø—Ç–æ–≤: {len(sam3_prompts)}")
        
        # –®–∞–≥ 3: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å SAM3
        segmentations = self.segment_with_sam3(
            image=image,
            prompts=sam3_prompts,
            confidence_threshold=confidence_threshold
        )
        
        # –°–≤—è–∑—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
        for i, seg in enumerate(segmentations):
            if i < len(detected_objects):
                seg.object_info = detected_objects[i]
        
        print(f"‚úÖ –°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(segmentations)}")
        for seg in segmentations:
            if seg.object_info:
                print(f"   - {seg.object_info.category} (score: {seg.score:.2f})")
        
        return segmentations
    
    def interactive_segment(
        self,
        image: Union[str, Image.Image, np.ndarray],
        description: str,
        detail_level: str = "detailed"
    ) -> List[SegmentationResult]:
        """
        –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: —Å–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ,
        –∑–∞—Ç–µ–º —Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            description: –û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏
            detail_level: –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        """
        image_b64 = self._image_to_base64(image)
        
        # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ü–µ–Ω—ã
        print(f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω—ã —Å Qwen VLM...")
        
        desc_url = f"{self.qwen_url}/api/{self.qwen_api_version}/image/description"
        desc_response = requests.post(desc_url, json={
            "image_base64": image_b64,
            "detail_level": detail_level,
            "prompt": f"Describe the image and identify: {description}"
        })
        desc_response.raise_for_status()
        
        scene_description = desc_response.json().get('description', '')
        print(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ü–µ–Ω—ã:\n{scene_description}\n")
        
        # –®–∞–≥ 2: –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        return self.analyze_and_segment(
            image=image,
            query=description,
            use_text_prompts=True
        )
    
    def spatial_segment(
        self,
        image: Union[str, Image.Image, np.ndarray],
        spatial_query: str
    ) -> List[SegmentationResult]:
        """
        –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å —É—á–µ—Ç–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            spatial_query: –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–æ–±—ä–µ–∫—Ç—ã –Ω–∞ —Å—Ç–æ–ª–µ")
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        """
        image_b64 = self._image_to_base64(image)
        
        print(f"üîç –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å Qwen VLM...")
        print(f"   –ó–∞–ø—Ä–æ—Å: {spatial_query}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ
        spatial_url = f"{self.qwen_url}/api/{self.qwen_api_version}/spatial/understanding"
        spatial_response = requests.post(spatial_url, json={
            "image_base64": image_b64,
            "query": spatial_query,
            "prompt": spatial_query
        })
        spatial_response.raise_for_status()
        
        spatial_result = spatial_response.json()
        print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:\n{spatial_result.get('answer', '')}\n")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        return self.analyze_and_segment(
            image=image,
            query=spatial_query,
            use_text_prompts=True
        )


# ==================== –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø ====================

def example_basic_usage():
    """–ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    print("=" * 60)
    print("–ü–†–ò–ú–ï–† 1: –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ")
    print("=" * 60)
    
    agent = SAM3QwenAgent(
        sam3_url="http://localhost:8000",
        qwen_url="http://localhost:8001"
    )
    
    # –ê–Ω–∞–ª–∏–∑ –∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
    results = agent.analyze_and_segment(
        image="path/to/image.jpg",
        query="–Ω–∞–π–¥–∏ –≤—Å–µ—Ö –ª—é–¥–µ–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏",
        categories=["person"],
        confidence_threshold=0.6
    )
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    for i, result in enumerate(results):
        print(f"\n–û–±—ä–µ–∫—Ç {i+1}:")
        print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {result.object_info.category}")
        print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.score:.2f}")
        print(f"  BBox: {result.bbox.to_list()}")
        if result.object_info.attributes:
            print(f"  –ê—Ç—Ä–∏–±—É—Ç—ã: {result.object_info.attributes}")


def example_multi_category():
    """–ü—Ä–∏–º–µ—Ä —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 2: –ü–æ–∏—Å–∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –æ–±—ä–µ–∫—Ç–æ–≤")
    print("=" * 60)
    
    agent = SAM3QwenAgent()
    
    results = agent.analyze_and_segment(
        image="street_scene.jpg",
        query="–Ω–∞–π–¥–∏ –≤—Å–µ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –∏ –ø–µ—à–µ—Ö–æ–¥–æ–≤",
        categories=["person", "car", "bicycle", "motorcycle"],
        use_text_prompts=True
    )
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    by_category = {}
    for result in results:
        cat = result.object_info.category
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(result)
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for category, items in by_category.items():
        print(f"  {category}: {len(items)} –æ–±—ä–µ–∫—Ç–æ–≤")


def example_interactive():
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 3: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è")
    print("=" * 60)
    
    agent = SAM3QwenAgent()
    
    results = agent.interactive_segment(
        image="room.jpg",
        description="–º–µ–±–µ–ª—å –∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞",
        detail_level="comprehensive"
    )
    
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(results)}")


def example_spatial():
    """–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 4: –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è")
    print("=" * 60)
    
    agent = SAM3QwenAgent()
    
    results = agent.spatial_segment(
        image="office.jpg",
        spatial_query="–∫–∞–∫–∏–µ –ø—Ä–µ–¥–º–µ—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –Ω–∞ —Ä–∞–±–æ—á–µ–º —Å—Ç–æ–ª–µ?"
    )
    
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —Å—Ç–æ–ª–µ: {len(results)}")


def example_advanced_workflow():
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π workflow —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 5: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π workflow")
    print("=" * 60)
    
    agent = SAM3QwenAgent()
    
    # –®–∞–≥ 1: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    image = "complex_scene.jpg"
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    image_b64 = agent._image_to_base64(image)
    desc_response = requests.post(
        f"{agent.qwen_url}/api/v1/image/description",
        json={
            "image_base64": image_b64,
            "detail_level": "comprehensive"
        }
    )
    description = desc_response.json().get('description', '')
    print(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ü–µ–Ω—ã:\n{description}\n")
    
    # –®–∞–≥ 2: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
    results = agent.analyze_and_segment(
        image=image,
        query="–Ω–∞–π–¥–∏ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –∫—Ä–∞—Å–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞",
        use_text_prompts=True,
        confidence_threshold=0.7
    )
    
    # –®–∞–≥ 3: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ score
    high_confidence_results = [r for r in results if r.score > 0.8]
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"  –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(results)}")
    print(f"  –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>0.8): {len(high_confidence_results)}")
    
    # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output = {
        "description": description,
        "total_objects": len(results),
        "objects": [
            {
                "category": r.object_info.category,
                "score": r.score,
                "bbox": r.bbox.to_list(),
                "attributes": r.object_info.attributes
            }
            for r in results
        ]
    }
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON")
    print(json.dumps(output, indent=2, ensure_ascii=False))


def example_bbox_vs_text():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ bounding box –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 6: BBox –ø—Ä–æ–º–ø—Ç—ã vs –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã")
    print("=" * 60)
    
    agent = SAM3QwenAgent()
    
    image = "test_image.jpg"
    
    # –° bounding box –ø—Ä–æ–º–ø—Ç–∞–º–∏
    print("\nüîπ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ BBox –ø—Ä–æ–º–ø—Ç–æ–≤:")
    results_bbox = agent.analyze_and_segment(
        image=image,
        query="–Ω–∞–π–¥–∏ –º–∞—à–∏–Ω—ã",
        categories=["car"],
        use_text_prompts=False  # –ò—Å–ø–æ–ª—å–∑—É–µ–º bbox
    )
    
    # –° —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
    print("\nüîπ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤:")
    results_text = agent.analyze_and_segment(
        image=image,
        query="–Ω–∞–π–¥–∏ –º–∞—à–∏–Ω—ã",
        categories=["car"],
        use_text_prompts=True  # –ò—Å–ø–æ–ª—å–∑—É–µ–º text
    )
    
    print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    print(f"  BBox –ø—Ä–æ–º–ø—Ç—ã: {len(results_bbox)} –æ–±—ä–µ–∫—Ç–æ–≤")
    print(f"  –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã: {len(results_text)} –æ–±—ä–µ–∫—Ç–æ–≤")


if __name__ == "__main__":
    """
    –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    
    –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:
    1. SAM3 API –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:8000
    2. Qwen VLM API –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:8001
    """
    
    # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –Ω—É–∂–Ω—ã–π –ø—Ä–∏–º–µ—Ä:
    
    # example_basic_usage()
    # example_multi_category()
    # example_interactive()
    # example_spatial()
    # example_advanced_workflow()
    # example_bbox_vs_text()
    
    print("\n‚úÖ –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
    print("–†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –Ω—É–∂–Ω—ã–π –ø—Ä–∏–º–µ—Ä –≤ –±–ª–æ–∫–µ if __name__ == '__main__'")
