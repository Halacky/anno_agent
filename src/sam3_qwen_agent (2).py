"""
SAM3 + Qwen VLM Agent
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤
"""

import requests
import base64
import json
import re
from typing import List, Dict, Optional, Union, Tuple
from dataclasses import dataclass
from io import BytesIO
from PIL import Image
import numpy as np


@dataclass
class BoundingBox:
    """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π bounding box [cx, cy, w, h]"""
    cx: float
    cy: float
    w: float
    h: float
    
    def to_list(self) -> List[float]:
        return [self.cx, self.cy, self.w, self.h]
    
    def to_xyxy(self, width: int, height: int) -> Tuple[int, int, int, int]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã [x1, y1, x2, y2]"""
        x1 = int((self.cx - self.w / 2) * width)
        y1 = int((self.cy - self.h / 2) * height)
        x2 = int((self.cx + self.w / 2) * width)
        y2 = int((self.cy + self.h / 2) * height)
        return (x1, y1, x2, y2)
    
    @classmethod
    def from_xyxy_normalized(cls, x1: float, y1: float, x2: float, y2: float):
        """–°–æ–∑–¥–∞—Ç—å –∏–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç [x1, y1, x2, y2]"""
        cx = (x1 + x2) / 2
        cy = (y1 + y2) / 2
        w = x2 - x1
        h = y2 - y1
        return cls(cx, cy, w, h)
    
    @classmethod
    def from_xyxy_absolute(cls, x1: int, y1: int, x2: int, y2: int, img_width: int, img_height: int):
        """–°–æ–∑–¥–∞—Ç—å –∏–∑ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç [x1, y1, x2, y2] –≤ –ø–∏–∫—Å–µ–ª—è—Ö"""
        x1_norm = x1 / img_width
        y1_norm = y1 / img_height
        x2_norm = x2 / img_width
        y2_norm = y2 / img_height
        return cls.from_xyxy_normalized(x1_norm, y1_norm, x2_norm, y2_norm)


@dataclass
class DetectedObject:
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏"""
    category: str
    bbox: BoundingBox
    confidence: float
    attributes: Optional[Dict] = None
    text_description: Optional[str] = None


@dataclass
class SegmentationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    mask: str  # RLE-encoded mask
    bbox: BoundingBox
    score: float
    object_info: Optional[DetectedObject] = None


class SAM3QwenAgent:
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è SAM3 –∏ Qwen VLM.
    
    Workflow:
    1. Qwen –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç—ã —á–µ—Ä–µ–∑ /v1/grounding/2d
    2. SAM3 –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ç–æ—á–Ω—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Qwen
    """
    
    def __init__(
        self,
        sam3_url: str = "http://localhost:8000",
        qwen_url: str = "http://localhost:8001",
        sam3_api_version: str = "v1",
        qwen_api_version: str = "v1"
    ):
        self.sam3_url = sam3_url.rstrip('/')
        self.qwen_url = qwen_url.rstrip('/')
        self.sam3_api_version = sam3_api_version
        self.qwen_api_version = qwen_api_version
        
    def _image_to_base64(self, image: Union[str, Image.Image, np.ndarray]) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64"""
        if isinstance(image, str):
            # –ï—Å–ª–∏ —ç—Ç–æ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            with open(image, 'rb') as f:
                return base64.b64encode(f.read()).decode('utf-8')
        elif isinstance(image, Image.Image):
            # PIL Image
            buffer = BytesIO()
            image.save(buffer, format='PNG')
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
        elif isinstance(image, np.ndarray):
            # NumPy array
            img = Image.fromarray(image)
            buffer = BytesIO()
            img.save(buffer, format='PNG')
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
        else:
            raise ValueError("Unsupported image type")
    
    def _get_image_size(self, image: Union[str, Image.Image, np.ndarray]) -> Tuple[int, int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (width, height)"""
        if isinstance(image, str):
            with Image.open(image) as img:
                return img.size
        elif isinstance(image, Image.Image):
            return image.size
        elif isinstance(image, np.ndarray):
            # NumPy array –≤ —Ñ–æ—Ä–º–∞—Ç–µ (height, width, channels)
            return (image.shape[1], image.shape[0])
        else:
            raise ValueError("Unsupported image type")
    
    def _parse_grounding_response(self, response_data: Dict, img_width: int, img_height: int) -> List[DetectedObject]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ Qwen grounding/2d
        
        –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ response_data["result"]:
        {
            "detections": [
                {
                    "label": "container",
                    "bbox": [x1, y1, x2, y2],  # –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ø–∏–∫—Å–µ–ª—è—Ö
                    "confidence": 0.95
                }
            ]
        }
        """
        detected_objects = []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = response_data.get('result', response_data.get('data', {}))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞
        detections = result.get('detections', [])
        
        # –ï—Å–ª–∏ detections –ø—É—Å—Ç–æ–π, –ø–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –ø–æ–ª—è
        if not detections:
            # –í–æ–∑–º–æ–∂–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –¥—Ä—É–≥–∏—Ö –ø–æ–ª—è—Ö
            if isinstance(result, list):
                detections = result
            elif 'objects' in result:
                detections = result['objects']
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ –¥–µ—Ç–µ–∫—Ü–∏–π –≤ –æ—Ç–≤–µ—Ç–µ: {len(detections)}")
        
        for detection in detections:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∫—É/–∫–∞—Ç–µ–≥–æ—Ä–∏—é
            label = detection.get('label') or detection.get('category') or detection.get('class', 'unknown')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º bbox - –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            bbox_raw = detection.get('bbox') or detection.get('box') or detection.get('bounding_box')
            
            if not bbox_raw:
                print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é –±–µ–∑ bbox: {detection}")
                continue
            
            # bbox –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º [x1, y1, x2, y2] –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—ë–º
            if isinstance(bbox_raw, list) and len(bbox_raw) == 4:
                x1, y1, x2, y2 = bbox_raw
            elif isinstance(bbox_raw, dict):
                x1 = bbox_raw.get('x1', bbox_raw.get('xmin', 0))
                y1 = bbox_raw.get('y1', bbox_raw.get('ymin', 0))
                x2 = bbox_raw.get('x2', bbox_raw.get('xmax', 0))
                y2 = bbox_raw.get('y2', bbox_raw.get('ymax', 0))
            else:
                print(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç bbox: {bbox_raw}")
                continue
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            bbox = BoundingBox.from_xyxy_absolute(
                int(x1), int(y1), int(x2), int(y2),
                img_width, img_height
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence = detection.get('confidence', detection.get('score', 1.0))
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
            attributes = detection.get('attributes')
            
            obj = DetectedObject(
                category=label,
                bbox=bbox,
                confidence=float(confidence),
                attributes=attributes,
                text_description=f"{label}"
            )
            
            detected_objects.append(obj)
            print(f"   ‚úì {label}: bbox={bbox.to_list()}, conf={confidence:.2f}")
        
        return detected_objects
    
    def detect_objects_with_qwen(
        self,
        image: Union[str, Image.Image, np.ndarray],
        categories: Optional[List[str]] = None,
        custom_prompt: Optional[str] = None
    ) -> List[DetectedObject]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é Qwen VLM –∏—Å–ø–æ–ª—å–∑—É—è /v1/grounding/2d endpoint
        
        Args:
            image: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, PIL Image –∏–ª–∏ NumPy array
            categories: –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
            custom_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è Qwen
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å bounding boxes
        """
        image_b64 = self._image_to_base64(image)
        img_width, img_height = self._get_image_size(image)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
        if custom_prompt:
            prompt = custom_prompt
        elif categories:
            # –§–æ—Ä–º–∞—Ç: "Detect all objects: cat1, cat2, cat3"
            cats_str = ", ".join(categories)
            prompt = f"Detect all objects: {cats_str}"
        else:
            prompt = "Detect all objects in the image"
        
        print(f"üîç Qwen grounding/2d –∑–∞–ø—Ä–æ—Å: {prompt}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º payload —Å–æ–≥–ª–∞—Å–Ω–æ API
        payload = {
            "image_base64": image_b64,
            "prompt": prompt
        }
        
        url = f"{self.qwen_url}/{self.qwen_api_version}/grounding/2d"
        
        try:
            response = requests.post(url, json=payload, timeout=60)
            response.raise_for_status()
        except requests.exceptions.ConnectionError as e:
            raise ConnectionError(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Qwen API –ø–æ –∞–¥—Ä–µ—Å—É {url}. "
                f"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ {self.qwen_url}"
            ) from e
        
        result = response.json()
        
        # –í—ã–≤–æ–¥–∏–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print(f"üìù –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Qwen:")
        print(json.dumps(result, indent=2, ensure_ascii=False)[:1000])
        
        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        detected_objects = self._parse_grounding_response(result, img_width, img_height)
        
        if not detected_objects:
            print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ–±—ä–µ–∫—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞ Qwen")
            print(f"   –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞: {list(result.keys())}")
        
        return detected_objects
    
    def segment_with_sam3(
        self,
        image: Union[str, Image.Image, np.ndarray],
        prompts: List[Dict],
        confidence_threshold: float = 0.5
    ) -> List[SegmentationResult]:
        """
        –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é SAM3
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            prompts: –°–ø–∏—Å–æ–∫ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è SAM3
            confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        """
        image_b64 = self._image_to_base64(image)
        
        payload = {
            "image": image_b64,
            "prompts": prompts,
            "confidence_threshold": confidence_threshold
        }
        
        url = f"{self.sam3_url}/api/{self.sam3_api_version}/image/segment"
        
        try:
            response = requests.post(url, json=payload, timeout=60)
            response.raise_for_status()
        except requests.exceptions.ConnectionError as e:
            raise ConnectionError(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ SAM3 API –ø–æ –∞–¥—Ä–µ—Å—É {url}. "
                f"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ {self.sam3_url}"
            ) from e
        
        result = response.json()
        
        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        segmentations = []
        for i in range(result['num_masks']):
            bbox_list = result['boxes'][i]
            bbox = BoundingBox(
                cx=bbox_list[0],
                cy=bbox_list[1],
                w=bbox_list[2],
                h=bbox_list[3]
            )
            
            seg = SegmentationResult(
                mask=result['masks'][i],
                bbox=bbox,
                score=result['scores'][i]
            )
            segmentations.append(seg)
        
        return segmentations
    
    def analyze_and_segment(
        self,
        image: Union[str, Image.Image, np.ndarray],
        query: str,
        categories: Optional[List[str]] = None,
        confidence_threshold: float = 0.5,
        use_text_prompts: bool = True,
        qwen_confidence_threshold: float = 0.3
    ) -> List[SegmentationResult]:
        """
        –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∞–Ω–∞–ª–∏–∑ —Å Qwen + —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å SAM3
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            query: –ó–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–Ω–∞–π–¥–∏ –≤—Å–µ –º–∞—à–∏–Ω—ã")
            categories: –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
            confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è SAM3
            use_text_prompts: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è SAM3
            qwen_confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ü–∏–π Qwen
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –æ–±—ä–µ–∫—Ç–∞—Ö
        """
        print("=" * 70)
        print(f"üîç –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å Qwen VLM...")
        print(f"   –ó–∞–ø—Ä–æ—Å: {query}")
        if categories:
            print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(categories)}")
        print("=" * 70)
        
        # –®–∞–≥ 1: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ —Å Qwen
        detected_objects = self.detect_objects_with_qwen(
            image=image,
            categories=categories,
            custom_prompt=query
        )
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        detected_objects = [
            obj for obj in detected_objects 
            if obj.confidence >= qwen_confidence_threshold
        ]
        
        print(f"\n‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (conf >= {qwen_confidence_threshold}): {len(detected_objects)}")
        for obj in detected_objects:
            print(f"   - {obj.category} (confidence: {obj.confidence:.2f})")
        
        if not detected_objects:
            print("‚ö†Ô∏è  –û–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –ø—Ä–æ—à–ª–∏ –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
            return []
        
        # –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è SAM3
        sam3_prompts = []
        
        for obj in detected_objects:
            if use_text_prompts:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
                text_description = obj.text_description or obj.category
                
                sam3_prompts.append({
                    "type": "text",
                    "text": text_description
                })
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º bounding box –ø—Ä–æ–º–ø—Ç
                sam3_prompts.append({
                    "type": "box",
                    "box": obj.bbox.to_list(),
                    "label": True
                })
        
        print(f"\nüéØ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å SAM3...")
        print(f"   –ü—Ä–æ–º–ø—Ç–æ–≤: {len(sam3_prompts)}")
        print(f"   –¢–∏–ø –ø—Ä–æ–º–ø—Ç–æ–≤: {'text' if use_text_prompts else 'box'}")
        
        # –®–∞–≥ 3: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å SAM3
        segmentations = self.segment_with_sam3(
            image=image,
            prompts=sam3_prompts,
            confidence_threshold=confidence_threshold
        )
        
        # –°–≤—è–∑—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
        for i, seg in enumerate(segmentations):
            if i < len(detected_objects):
                seg.object_info = detected_objects[i]
        
        print(f"\n‚úÖ –°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(segmentations)}")
        for seg in segmentations:
            if seg.object_info:
                print(f"   - {seg.object_info.category} (SAM3 score: {seg.score:.2f})")
        
        print("=" * 70)
        
        return segmentations
    
    def interactive_segment(
        self,
        image: Union[str, Image.Image, np.ndarray],
        description: str,
        detail_level: str = "detailed"
    ) -> List[SegmentationResult]:
        """
        –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: —Å–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ,
        –∑–∞—Ç–µ–º —Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            description: –û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏
            detail_level: –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        """
        image_b64 = self._image_to_base64(image)
        
        # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ü–µ–Ω—ã
        print(f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω—ã —Å Qwen VLM...")
        
        desc_url = f"{self.qwen_url}/{self.qwen_api_version}/image/description"
        desc_response = requests.post(desc_url, json={
            "image_base64": image_b64,
            "detail_level": detail_level,
            "prompt": f"Describe the image and identify: {description}"
        }, timeout=60)
        desc_response.raise_for_status()
        
        scene_description = desc_response.json().get('description', '')
        print(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ü–µ–Ω—ã:\n{scene_description}\n")
        
        # –®–∞–≥ 2: –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        return self.analyze_and_segment(
            image=image,
            query=description,
            use_text_prompts=True
        )
    
    def spatial_segment(
        self,
        image: Union[str, Image.Image, np.ndarray],
        spatial_query: str
    ) -> List[SegmentationResult]:
        """
        –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å —É—á–µ—Ç–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            spatial_query: –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–æ–±—ä–µ–∫—Ç—ã –Ω–∞ —Å—Ç–æ–ª–µ")
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        """
        image_b64 = self._image_to_base64(image)
        
        print(f"üîç –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å Qwen VLM...")
        print(f"   –ó–∞–ø—Ä–æ—Å: {spatial_query}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ
        spatial_url = f"{self.qwen_url}/{self.qwen_api_version}/spatial/understanding"
        
        try:
            spatial_response = requests.post(spatial_url, json={
                "image_base64": image_b64,
                "query": spatial_query,
                "prompt": spatial_query
            }, timeout=60)
            spatial_response.raise_for_status()
            
            spatial_result = spatial_response.json()
            print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:\n{spatial_result.get('answer', '')}\n")
        except requests.exceptions.HTTPError:
            print("‚ö†Ô∏è  Endpoint spatial/understanding –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º grounding/2d")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        return self.analyze_and_segment(
            image=image,
            query=spatial_query,
            use_text_prompts=True
        )


# ==================== –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø ====================

def example_basic_usage():
    """–ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    print("=" * 60)
    print("–ü–†–ò–ú–ï–† 1: –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ")
    print("=" * 60)
    
    agent = SAM3QwenAgent(
        sam3_url="http://localhost:8000",
        qwen_url="http://localhost:8001"
    )
    
    # –í–ê–ñ–ù–û: –£–∫–∞–∂–∏—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    image_path = "/home/golovanks/projects/sgp_kras/MainHanlder/CT/anno_agent-main/tmp_cvat_download/images/00001.jpg"
    
    try:
        # –ê–Ω–∞–ª–∏–∑ –∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        results = agent.analyze_and_segment(
            image=image_path,
            query="Detect all objects: containers",
            categories=["container"],
            confidence_threshold=0.5,
            qwen_confidence_threshold=0.3
        )
        
        print(f"\nüìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ: {len(results)} –æ–±—ä–µ–∫—Ç–æ–≤\n")
        
        for i, result in enumerate(results):
            print(f"–û–±—ä–µ–∫—Ç {i+1}:")
            if result.object_info:
                print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {result.object_info.category}")
                print(f"  Qwen confidence: {result.object_info.confidence:.2f}")
                if result.object_info.text_description:
                    print(f"  –û–ø–∏—Å–∞–Ω–∏–µ: {result.object_info.text_description}")
            print(f"  SAM3 score: {result.score:.2f}")
            print(f"  BBox (normalized): {result.bbox.to_list()}")
            print()
            
    except ConnectionError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        print("\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä—ã –∑–∞–ø—É—â–µ–Ω—ã:")
        print("  - SAM3 API: http://localhost:8000")
        print("  - Qwen API: http://localhost:8001")
    except FileNotFoundError:
        print(f"\n‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}")
        print("–£–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


def example_bbox_vs_text():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ bbox –∏ text –ø—Ä–æ–º–ø—Ç–æ–≤"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ BBox vs Text –ø—Ä–æ–º–ø—Ç–æ–≤")
    print("=" * 60)
    
    agent = SAM3QwenAgent()
    image_path = "/home/golovanks/projects/sgp_kras/MainHanlder/CT/anno_agent-main/tmp_cvat_download/images/00001.jpg"
    
    try:
        # –¢–µ—Å—Ç —Å bbox –ø—Ä–æ–º–ø—Ç–∞–º–∏
        print("\nüîπ –¢–ï–°–¢ 1: BBox –ø—Ä–æ–º–ø—Ç—ã")
        results_bbox = agent.analyze_and_segment(
            image=image_path,
            query="Detect all objects: containers",
            categories=["container"],
            use_text_prompts=False  # BBox
        )
        
        # –¢–µ—Å—Ç —Å text –ø—Ä–æ–º–ø—Ç–∞–º–∏
        print("\nüîπ –¢–ï–°–¢ 2: Text –ø—Ä–æ–º–ø—Ç—ã")
        results_text = agent.analyze_and_segment(
            image=image_path,
            query="Detect all objects: containers",
            categories=["container"],
            use_text_prompts=True  # Text
        )
        
        print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï:")
        print(f"  BBox –ø—Ä–æ–º–ø—Ç—ã: {len(results_bbox)} –æ–±—ä–µ–∫—Ç–æ–≤")
        print(f"  Text –ø—Ä–æ–º–ø—Ç—ã: {len(results_text)} –æ–±—ä–µ–∫—Ç–æ–≤")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")


def example_simple_test():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
    print("=" * 60)
    
    agent = SAM3QwenAgent()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Qwen API
    print("\n1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ Qwen API...")
    try:
        response = requests.get(f"{agent.qwen_url}/health", timeout=5)
        if response.status_code == 200:
            print("   ‚úÖ Qwen API –¥–æ—Å—Ç—É–ø–µ–Ω")
        else:
            print(f"   ‚ö†Ô∏è  Qwen API –≤–µ—Ä–Ω—É–ª –∫–æ–¥: {response.status_code}")
    except Exception as e:
        print(f"   ‚ùå Qwen API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ SAM3 API
    print("\n2Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ SAM3 API...")
    try:
        response = requests.get(f"{agent.sam3_url}/health", timeout=5)
        if response.status_code == 200:
            print("   ‚úÖ SAM3 API –¥–æ—Å—Ç—É–ø–µ–Ω")
        else:
            print(f"   ‚ö†Ô∏è  SAM3 API –≤–µ—Ä–Ω—É–ª –∫–æ–¥: {response.status_code}")
    except Exception as e:
        print(f"   ‚ùå SAM3 API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")


if __name__ == "__main__":
    """
    –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    
    –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:
    1. SAM3 API –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:8000
    2. Qwen VLM API –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:8001
    """
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    example_simple_test()
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–º–µ—Ä
    example_basic_usage()
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤
    # example_bbox_vs_text()
