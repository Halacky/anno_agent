# üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞ 5 –º–∏–Ω—É—Ç

```bash
# 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞
git clone <repo_url>
cd ai_annotation_agent
pip install poetry
poetry install

# 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞
cp .env.example .env
# –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ .env —Ñ–∞–π–ª

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
poetry run python -c "from src.agents.video_annotation_agent import VideoAnnotationAgent; print('OK')"
```

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ CLI

### 1Ô∏è‚É£ –ë–∞–∑–æ–≤–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –≤–∏–¥–µ–æ

```bash
poetry run python -m src.utils.cli video-basic \
  data/input/video.mp4 \
  --task "Detect all vehicles and pedestrians" \
  --max-frames 50 \
  --output output/my_task
```

**–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç:**
- –ò–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –¥–æ 50 –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ
- –ö–∞–∂–¥—ã–π –∫–∞–¥—Ä –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å—é Qwen3-VL
- –°–æ–∑–¥–∞—é—Ç—Å—è JSON —Ñ–∞–π–ª—ã —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `output/my_task_TIMESTAMP/`

### 2Ô∏è‚É£ –†–∞–∑–º–µ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å –æ–ø–æ—Ä–Ω—ã–º–∏ –∫–∞–¥—Ä–∞–º–∏

```bash
# –°–Ω–∞—á–∞–ª–∞ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –æ–ø–æ—Ä–Ω—ã–µ –∫–∞–¥—Ä—ã —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ –≤ data/keyframes/
# –§–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å: frame_001.jpg, frame_001_annotation.json, –∏ —Ç.–¥.

poetry run python -m src.utils.cli video-keyframes \
  data/input/video.mp4 \
  data/keyframes/ \
  --task "Track vehicles maintaining consistent IDs" \
  --max-frames 100
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ç–∫–∏ –ø–æ –≤—Å–µ–º—É –≤–∏–¥–µ–æ
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ tracking ID –æ–±—ä–µ–∫—Ç–æ–≤
- –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –±–ª–∞–≥–æ–¥–∞—Ä—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–º –ø—Ä–∏–º–µ—Ä–∞–º

### 3Ô∏è‚É£ –†–∞–∑–º–µ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏

```bash
# –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –≤ data/examples/:
# - image1.jpg, image1_annotation.json
# - image2.jpg, image2_annotation.json

poetry run python -m src.utils.cli images-examples \
  data/images/unlabeled/ \
  data/examples/ \
  --task "Annotate products for e-commerce catalog"
```

**Few-shot learning:**
- –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –Ω–∞ –≤–∞—à–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
- –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —Å—Ç–∏–ª—å —Ä–∞–∑–º–µ—Ç–∫–∏
- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á

### 4Ô∏è‚É£ –ë–∞–∑–æ–≤–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

```bash
poetry run python -m src.utils.cli images-basic \
  data/images/raw/ \
  --task "Detect objects in street scenes"
```

**–ü—Ä–æ—Å—Ç–µ–π—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç:**
- –ù–µ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∏–º–µ—Ä–æ–≤
- –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é
- –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

## –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ü—Ä–∏–º–µ—Ä 1: –°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ

```python
# annotate_video.py
import asyncio
from pathlib import Path
from src.agents.video_annotation_agent import VideoAnnotationAgent

async def main():
    agent = VideoAnnotationAgent()
    
    result = await agent.annotate_video_basic(
        video_path=Path("input.mp4"),
        task_description="""
        Detect:
        - All vehicles (cars, trucks, buses)
        - Pedestrians
        - Traffic signs
        Provide bounding boxes and confidence scores.
        """,
        max_frames=50
    )
    
    print(f"‚úÖ Done! Check: {result['output_dir']}")
    await agent.cleanup()

asyncio.run(main())
```

–ó–∞–ø—É—Å–∫:
```bash
poetry run python annotate_video.py
```

### –ü—Ä–∏–º–µ—Ä 2: Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤

```python
# batch_annotate.py
import asyncio
from pathlib import Path
from src.utils.batch_processor import BatchProcessor
from src.agents.image_annotation_agent import ImageAnnotationAgent

async def main():
    processor = BatchProcessor(max_concurrent=3)
    agent = ImageAnnotationAgent()
    
    # –ù–∞–π—Ç–∏ –≤—Å–µ –ø–∞–ø–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    input_dirs = list(Path("data/batches").glob("batch_*"))
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∑–∞–¥–∞—á–∏
    tasks = []
    for dir_path in input_dirs:
        tasks.append((
            (),  # args
            {    # kwargs
                "images_dir": dir_path,
                "task_description": "Standard object detection",
                "output_dir": Path(f"output/{dir_path.name}")
            }
        ))
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    results = await processor.process_batch(
        tasks,
        agent.annotate_images_basic,
        desc="Batch annotation"
    )
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    successful = sum(1 for r in results if r["success"])
    print(f"‚úÖ Processed {successful}/{len(results)} batches")
    
    await agent.cleanup()

asyncio.run(main())
```

–ó–∞–ø—É—Å–∫:
```bash
poetry run python batch_annotate.py
```

### –ü—Ä–∏–º–µ—Ä 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ pipeline

```python
# pipeline.py
import asyncio
from pathlib import Path
from src.agents.video_annotation_agent import VideoAnnotationAgent
from src.tools.validation_tools.py import AnnotationValidator

async def video_annotation_pipeline(video_path: Path):
    """–ü–æ–ª–Ω—ã–π pipeline: —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è ‚Üí –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è ‚Üí –≤–∞–ª–∏–¥–∞—Ü–∏—è"""
    
    # 1. –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è
    agent = VideoAnnotationAgent()
    result = await agent.annotate_video_basic(
        video_path=video_path,
        task_description="Detect objects",
        max_frames=100
    )
    await agent.cleanup()
    
    # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è
    validator = AnnotationValidator()
    annotations_dir = Path(result['output_dir']) / 'annotations'
    
    validation_results = []
    for ann_file in annotations_dir.glob("*.json"):
        validation = validator.validate_annotation_file(ann_file)
        validation_results.append(validation)
    
    # 3. –û—Ç—á–µ—Ç
    valid_count = sum(1 for v in validation_results if v["valid"])
    print(f"Validation: {valid_count}/{len(validation_results)} valid")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å –æ—à–∏–±–∫–∏
    for v in validation_results:
        if not v["valid"]:
            print(f"‚ùå {v['file']}: {v['errors']}")
    
    return result

# –ó–∞–ø—É—Å–∫
asyncio.run(video_annotation_pipeline(Path("video.mp4")))
```

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

### –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

```
data/
‚îú‚îÄ‚îÄ input/
‚îÇ   ‚îú‚îÄ‚îÄ video1.mp4
‚îÇ   ‚îî‚îÄ‚îÄ video2.mp4
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ unlabeled/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img001.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img002.jpg
‚îÇ   ‚îî‚îÄ‚îÄ examples/
‚îÇ       ‚îú‚îÄ‚îÄ example1.jpg
‚îÇ       ‚îú‚îÄ‚îÄ example1_annotation.json
‚îÇ       ‚îú‚îÄ‚îÄ example2.jpg
‚îÇ       ‚îî‚îÄ‚îÄ example2_annotation.json
‚îî‚îÄ‚îÄ keyframes/
    ‚îú‚îÄ‚îÄ keyframe_001.jpg
    ‚îú‚îÄ‚îÄ keyframe_001_annotation.json
    ‚îú‚îÄ‚îÄ keyframe_050.jpg
    ‚îî‚îÄ‚îÄ keyframe_050_annotation.json
```

### –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

```
output/
‚îî‚îÄ‚îÄ video_basic_20260114_153045/
    ‚îú‚îÄ‚îÄ frames/
    ‚îÇ   ‚îú‚îÄ‚îÄ frame_000001.jpg
    ‚îÇ   ‚îú‚îÄ‚îÄ frame_000002.jpg
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ annotations/
    ‚îÇ   ‚îú‚îÄ‚îÄ frame_000001.json
    ‚îÇ   ‚îú‚îÄ‚îÄ frame_000002.json
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ metadata/
        ‚îî‚îÄ‚îÄ task_metadata.json
```

### –§–æ—Ä–º–∞—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ (JSON)

```json
{
  "annotations": [
    {
      "object": "car",
      "bbox": [100, 150, 300, 400],
      "confidence": 0.95,
      "attributes": {
        "color": "red",
        "type": "sedan",
        "tracking_id": "vehicle_001"
      }
    },
    {
      "object": "person",
      "bbox": [450, 200, 550, 500],
      "confidence": 0.89,
      "attributes": {
        "activity": "walking",
        "clothing": "casual"
      }
    }
  ],
  "metadata": {
    "image_analysis": "Street scene with light traffic",
    "frame_number": 42,
    "timestamp": "2026-01-14T15:30:45",
    "weather": "clear",
    "lighting": "daylight"
  }
}
```

## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤

### –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏

```python
from langchain.prompts import PromptTemplate

custom_prompt = PromptTemplate(
    input_variables=["task_description", "frame_number"],
    template="""
You are a specialized medical image annotator.

Task: {task_description}
Frame: {frame_number}

Requirements:
1. Identify all anatomical structures
2. Mark any anomalies or pathologies
3. Provide confidence scores
4. Use medical terminology
5. Include measurements if applicable

Output format: JSON with structure:
{{
  "anatomical_structures": [...],
  "anomalies": [...],
  "measurements": {{}},
  "clinical_notes": "..."
}}
"""
)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
from src.agents.video_annotation_agent import VideoAnnotationAgent

agent = VideoAnnotationAgent()
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ monkey patching –∏–ª–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—é –∫–ª–∞—Å—Å–∞
```

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ—Ç–ª–∞–¥–∫–∞

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤

```bash
# –õ–æ–≥–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
tail -f logs/app_$(date +%Y-%m-%d).log

# –ü–æ–∏—Å–∫ –æ—à–∏–±–æ–∫
grep ERROR logs/app_*.log

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
grep "Annotating" logs/app_*.log | wc -l
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π

```python
# validate_all.py
from pathlib import Path
from src.tools.validation_tools import AnnotationValidator
import json

validator = AnnotationValidator()
annotations_dir = Path("output/my_task_20260114_153045/annotations")

all_valid = True
for ann_file in annotations_dir.glob("*.json"):
    result = validator.validate_annotation_file(ann_file)
    
    if not result["valid"]:
        print(f"‚ùå {ann_file.name}")
        for error in result["errors"]:
            print(f"  - {error}")
        all_valid = False

if all_valid:
    print("‚úÖ All annotations are valid!")
```

## Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: "Connection refused" –∫ Qwen API

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ API –∑–∞–ø—É—â–µ–Ω
curl http://localhost:8000/health

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env
cat .env | grep QWEN_API_URL
```

### –ü—Ä–æ–±–ª–µ–º–∞: –°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

```python
# –†–µ—à–µ–Ω–∏–µ: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ batch processing —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
from src.utils.batch_processor import BatchProcessor

processor = BatchProcessor(max_concurrent=5)  # –£–≤–µ–ª–∏—á—å—Ç–µ —á–∏—Å–ª–æ
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏

```python
# –†–µ—à–µ–Ω–∏–µ 1: –£–ª—É—á—à–∏—Ç–µ –ø—Ä–æ–º–ø—Ç
task_description = """
Be very specific and detailed.
For each object provide:
- Exact bounding box coordinates
- High confidence (>0.8) detections only
- Detailed attributes
"""

# –†–µ—à–µ–Ω–∏–µ 2: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ few-shot learning —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
# –°–º. –ü—Ä–∏–º–µ—Ä 3
```

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –±–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä
2. üìù –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –ø—Ä–æ–º–ø—Ç—ã –ø–æ–¥ –≤–∞—à—É –∑–∞–¥–∞—á—É
3. üéØ –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –¥–ª—è few-shot learning
4. üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–µ batch –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
5. ‚úîÔ∏è –í–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
6. üîÑ –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —É–ª—É—á—à–∞–π—Ç–µ –ø—Ä–æ–º–ø—Ç—ã

## –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

```bash
# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
poetry run pytest

# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
poetry run black src/
poetry run ruff check src/

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤
poetry run mypy src/

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
poetry run pdoc src/ --html --output-dir docs/
```